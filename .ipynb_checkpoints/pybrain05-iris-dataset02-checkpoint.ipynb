{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importando as lib do pybrain\n",
    "from pybrain.tools.shortcuts import buildNetwork\n",
    "from pybrain.supervised import BackpropTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando sklearn\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#carregando o dataset iris\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]\n",
      " [ 5.4  3.9  1.7  0.4]\n",
      " [ 4.6  3.4  1.4  0.3]\n",
      " [ 5.   3.4  1.5  0.2]\n",
      " [ 4.4  2.9  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.4  3.7  1.5  0.2]\n",
      " [ 4.8  3.4  1.6  0.2]\n",
      " [ 4.8  3.   1.4  0.1]\n",
      " [ 4.3  3.   1.1  0.1]\n",
      " [ 5.8  4.   1.2  0.2]\n",
      " [ 5.7  4.4  1.5  0.4]\n",
      " [ 5.4  3.9  1.3  0.4]\n",
      " [ 5.1  3.5  1.4  0.3]\n",
      " [ 5.7  3.8  1.7  0.3]\n",
      " [ 5.1  3.8  1.5  0.3]\n",
      " [ 5.4  3.4  1.7  0.2]\n",
      " [ 5.1  3.7  1.5  0.4]\n",
      " [ 4.6  3.6  1.   0.2]\n",
      " [ 5.1  3.3  1.7  0.5]\n",
      " [ 4.8  3.4  1.9  0.2]\n",
      " [ 5.   3.   1.6  0.2]\n",
      " [ 5.   3.4  1.6  0.4]\n",
      " [ 5.2  3.5  1.5  0.2]\n",
      " [ 5.2  3.4  1.4  0.2]\n",
      " [ 4.7  3.2  1.6  0.2]\n",
      " [ 4.8  3.1  1.6  0.2]\n",
      " [ 5.4  3.4  1.5  0.4]\n",
      " [ 5.2  4.1  1.5  0.1]\n",
      " [ 5.5  4.2  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.   3.2  1.2  0.2]\n",
      " [ 5.5  3.5  1.3  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 4.4  3.   1.3  0.2]\n",
      " [ 5.1  3.4  1.5  0.2]\n",
      " [ 5.   3.5  1.3  0.3]\n",
      " [ 4.5  2.3  1.3  0.3]\n",
      " [ 4.4  3.2  1.3  0.2]\n",
      " [ 5.   3.5  1.6  0.6]\n",
      " [ 5.1  3.8  1.9  0.4]\n",
      " [ 4.8  3.   1.4  0.3]\n",
      " [ 5.1  3.8  1.6  0.2]\n",
      " [ 4.6  3.2  1.4  0.2]\n",
      " [ 5.3  3.7  1.5  0.2]\n",
      " [ 5.   3.3  1.4  0.2]\n",
      " [ 7.   3.2  4.7  1.4]\n",
      " [ 6.4  3.2  4.5  1.5]\n",
      " [ 6.9  3.1  4.9  1.5]\n",
      " [ 5.5  2.3  4.   1.3]\n",
      " [ 6.5  2.8  4.6  1.5]\n",
      " [ 5.7  2.8  4.5  1.3]\n",
      " [ 6.3  3.3  4.7  1.6]\n",
      " [ 4.9  2.4  3.3  1. ]\n",
      " [ 6.6  2.9  4.6  1.3]\n",
      " [ 5.2  2.7  3.9  1.4]\n",
      " [ 5.   2.   3.5  1. ]\n",
      " [ 5.9  3.   4.2  1.5]\n",
      " [ 6.   2.2  4.   1. ]\n",
      " [ 6.1  2.9  4.7  1.4]\n",
      " [ 5.6  2.9  3.6  1.3]\n",
      " [ 6.7  3.1  4.4  1.4]\n",
      " [ 5.6  3.   4.5  1.5]\n",
      " [ 5.8  2.7  4.1  1. ]\n",
      " [ 6.2  2.2  4.5  1.5]\n",
      " [ 5.6  2.5  3.9  1.1]\n",
      " [ 5.9  3.2  4.8  1.8]\n",
      " [ 6.1  2.8  4.   1.3]\n",
      " [ 6.3  2.5  4.9  1.5]\n",
      " [ 6.1  2.8  4.7  1.2]\n",
      " [ 6.4  2.9  4.3  1.3]\n",
      " [ 6.6  3.   4.4  1.4]\n",
      " [ 6.8  2.8  4.8  1.4]\n",
      " [ 6.7  3.   5.   1.7]\n",
      " [ 6.   2.9  4.5  1.5]\n",
      " [ 5.7  2.6  3.5  1. ]\n",
      " [ 5.5  2.4  3.8  1.1]\n",
      " [ 5.5  2.4  3.7  1. ]\n",
      " [ 5.8  2.7  3.9  1.2]\n",
      " [ 6.   2.7  5.1  1.6]\n",
      " [ 5.4  3.   4.5  1.5]\n",
      " [ 6.   3.4  4.5  1.6]\n",
      " [ 6.7  3.1  4.7  1.5]\n",
      " [ 6.3  2.3  4.4  1.3]\n",
      " [ 5.6  3.   4.1  1.3]\n",
      " [ 5.5  2.5  4.   1.3]\n",
      " [ 5.5  2.6  4.4  1.2]\n",
      " [ 6.1  3.   4.6  1.4]\n",
      " [ 5.8  2.6  4.   1.2]\n",
      " [ 5.   2.3  3.3  1. ]\n",
      " [ 5.6  2.7  4.2  1.3]\n",
      " [ 5.7  3.   4.2  1.2]\n",
      " [ 5.7  2.9  4.2  1.3]\n",
      " [ 6.2  2.9  4.3  1.3]\n",
      " [ 5.1  2.5  3.   1.1]\n",
      " [ 5.7  2.8  4.1  1.3]\n",
      " [ 6.3  3.3  6.   2.5]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 7.1  3.   5.9  2.1]\n",
      " [ 6.3  2.9  5.6  1.8]\n",
      " [ 6.5  3.   5.8  2.2]\n",
      " [ 7.6  3.   6.6  2.1]\n",
      " [ 4.9  2.5  4.5  1.7]\n",
      " [ 7.3  2.9  6.3  1.8]\n",
      " [ 6.7  2.5  5.8  1.8]\n",
      " [ 7.2  3.6  6.1  2.5]\n",
      " [ 6.5  3.2  5.1  2. ]\n",
      " [ 6.4  2.7  5.3  1.9]\n",
      " [ 6.8  3.   5.5  2.1]\n",
      " [ 5.7  2.5  5.   2. ]\n",
      " [ 5.8  2.8  5.1  2.4]\n",
      " [ 6.4  3.2  5.3  2.3]\n",
      " [ 6.5  3.   5.5  1.8]\n",
      " [ 7.7  3.8  6.7  2.2]\n",
      " [ 7.7  2.6  6.9  2.3]\n",
      " [ 6.   2.2  5.   1.5]\n",
      " [ 6.9  3.2  5.7  2.3]\n",
      " [ 5.6  2.8  4.9  2. ]\n",
      " [ 7.7  2.8  6.7  2. ]\n",
      " [ 6.3  2.7  4.9  1.8]\n",
      " [ 6.7  3.3  5.7  2.1]\n",
      " [ 7.2  3.2  6.   1.8]\n",
      " [ 6.2  2.8  4.8  1.8]\n",
      " [ 6.1  3.   4.9  1.8]\n",
      " [ 6.4  2.8  5.6  2.1]\n",
      " [ 7.2  3.   5.8  1.6]\n",
      " [ 7.4  2.8  6.1  1.9]\n",
      " [ 7.9  3.8  6.4  2. ]\n",
      " [ 6.4  2.8  5.6  2.2]\n",
      " [ 6.3  2.8  5.1  1.5]\n",
      " [ 6.1  2.6  5.6  1.4]\n",
      " [ 7.7  3.   6.1  2.3]\n",
      " [ 6.3  3.4  5.6  2.4]\n",
      " [ 6.4  3.1  5.5  1.8]\n",
      " [ 6.   3.   4.8  1.8]\n",
      " [ 6.9  3.1  5.4  2.1]\n",
      " [ 6.7  3.1  5.6  2.4]\n",
      " [ 6.9  3.1  5.1  2.3]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 6.8  3.2  5.9  2.3]\n",
      " [ 6.7  3.3  5.7  2.5]\n",
      " [ 6.7  3.   5.2  2.3]\n",
      " [ 6.3  2.5  5.   1.9]\n",
      " [ 6.5  3.   5.2  2. ]\n",
      " [ 6.2  3.4  5.4  2.3]\n",
      " [ 5.9  3.   5.1  1.8]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "#pegando as entradas X e as saidas Y\n",
    "x, y = iris.data,  iris.target\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybrain.datasets.classification import ClassificationDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = ClassificationDataSet(4, 1, nb_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adicionando as amostras\n",
    "for i in range(len(x)):\n",
    "    dt.addSample(x[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "#particionando os dataset para treino e testes\n",
    "#teste: objetivo DE AVALIAR O DESEMPENHO DO CLASSIFICADOR\n",
    "#treino: objetivo DE AJUSTAR OS PESOS DO CLASSIFICADOR\n",
    "train_data, part_data = dt.splitWithProportion(0.6) #60% do dataset serão para treino e 40% para teste\n",
    "print(len(train_data))\n",
    "print(len(part_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dividindo os dados entre teste e validação\n",
    "#conjunto de teste: objetivo DE AJUSTAR OS PARAMETROS DO CLASSIFICADOR\n",
    "#conjunto de validação: objetivo DE TESTE O \"VÍCIO DA REDE NEURAL\". O rede costumar decorar padrões\n",
    "test_data, val_data = part_data.splitWithProportion(0.5) #50% dos dados para teste e 50% para validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#construindo a rede neural\n",
    "rede = buildNetwork(dt.indim,3, dt.outdim)\n",
    "trainer = BackpropTrainer(rede, dataset=train_data, learningrate=0.01, momentum=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error:  0.391085633386\n",
      "Total error:  0.28442351527\n",
      "Total error:  0.245474742177\n",
      "Total error:  0.216404145328\n",
      "Total error:  0.191906083596\n",
      "Total error:  0.169198018659\n",
      "Total error:  0.149173553835\n",
      "Total error:  0.131247340362\n",
      "Total error:  0.11588311004\n",
      "Total error:  0.102536258138\n",
      "Total error:  0.0906961067669\n",
      "Total error:  0.0820408724251\n",
      "Total error:  0.0735820377787\n",
      "Total error:  0.0672329468326\n",
      "Total error:  0.0615123031561\n",
      "Total error:  0.0562236132326\n",
      "Total error:  0.0527915613438\n",
      "Total error:  0.0490226603148\n",
      "Total error:  0.0458798860811\n",
      "Total error:  0.0428980010865\n",
      "Total error:  0.0399278766379\n",
      "Total error:  0.0385901628656\n",
      "Total error:  0.0370591164542\n",
      "Total error:  0.034977764606\n",
      "Total error:  0.0339495234413\n",
      "Total error:  0.032575011443\n",
      "Total error:  0.031185779277\n",
      "Total error:  0.0305643931357\n",
      "Total error:  0.0291753128841\n",
      "Total error:  0.0282209293612\n",
      "Total error:  0.0278610527143\n",
      "Total error:  0.0271535277187\n",
      "Total error:  0.0257355092612\n",
      "Total error:  0.0252466669246\n",
      "Total error:  0.0254907874611\n",
      "Total error:  0.024652126777\n",
      "Total error:  0.0243169524588\n",
      "Total error:  0.0239659937988\n",
      "Total error:  0.0234852645239\n",
      "Total error:  0.0210050979507\n",
      "Total error:  0.0224274388002\n",
      "Total error:  0.0231213347874\n",
      "Total error:  0.0224496763574\n",
      "Total error:  0.0224005481226\n",
      "Total error:  0.0214822194195\n",
      "Total error:  0.021717087168\n",
      "Total error:  0.0213579619269\n",
      "Total error:  0.0221770920994\n",
      "Total error:  0.0211337228245\n",
      "Total error:  0.0210543106577\n",
      "Total error:  0.0213709712861\n",
      "Total error:  0.0197170524209\n",
      "Total error:  0.0208907954342\n",
      "Total error:  0.0213395149989\n",
      "Total error:  0.0207597374719\n",
      "Total error:  0.0201777874299\n",
      "Total error:  0.0203212867805\n",
      "Total error:  0.0205987712226\n",
      "Total error:  0.0205653929015\n",
      "Total error:  0.0207020997231\n",
      "Total error:  0.0200301097891\n",
      "Total error:  0.0202963428485\n",
      "Total error:  0.0195832415881\n",
      "Total error:  0.0203934008568\n",
      "Total error:  0.0196911716545\n",
      "Total error:  0.0202013084957\n",
      "Total error:  0.0196978993238\n",
      "Total error:  0.0195993418275\n",
      "Total error:  0.019919612272\n",
      "Total error:  0.0198219830607\n",
      "Total error:  0.0191588427891\n",
      "Total error:  0.0196979016688\n",
      "Total error:  0.0196796127951\n",
      "Total error:  0.0191214234948\n",
      "Total error:  0.0199828180671\n",
      "Total error:  0.0190269262503\n",
      "Total error:  0.0195847313944\n",
      "Total error:  0.0188010038184\n",
      "Total error:  0.0195856857699\n",
      "Total error:  0.0186743889168\n",
      "Total error:  0.0183455025717\n",
      "Total error:  0.0174659676793\n",
      "Total error:  0.0208316730242\n",
      "Total error:  0.0192211085931\n",
      "Total error:  0.0191519289057\n",
      "Total error:  0.0199625613272\n",
      "Total error:  0.0192399370668\n",
      "Total error:  0.0191124258448\n",
      "Total error:  0.0187058191973\n",
      "Total error:  0.0186850487209\n",
      "Total error:  0.0192593197595\n",
      "Total error:  0.0192022998541\n",
      "Total error:  0.0193440364129\n",
      "Total error:  0.0171537915474\n",
      "Total error:  0.0198612375003\n",
      "Total error:  0.0189846830289\n",
      "Total error:  0.0186480845771\n",
      "Total error:  0.0184347839991\n",
      "Total error:  0.0197116862967\n",
      "Total error:  0.0177128323966\n",
      "Total error:  0.0194173377552\n",
      "('train-errors:', '[0.391086 , 0.284424 , 0.245475 , 0.216404 , 0.191906 , 0.169198 , 0.149174 , 0.131247 , 0.115883 , 0.102536 , 0.090696 , 0.082041 , 0.073582 , 0.067233 , 0.061512 , 0.056224 , 0.052792 , 0.049023 , 0.04588  , 0.042898 , 0.039928 , 0.03859  , 0.037059 , 0.034978 , 0.03395  , 0.032575 , 0.031186 , 0.030564 , 0.029175 , 0.028221 , 0.027861 , 0.027154 , 0.025736 , 0.025247 , 0.025491 , 0.024652 , 0.024317 , 0.023966 , 0.023485 , 0.021005 , 0.022427 , 0.023121 , 0.02245  , 0.022401 , 0.021482 , 0.021717 , 0.021358 , 0.022177 , 0.021134 , 0.021054 , 0.021371 , 0.019717 , 0.020891 , 0.02134  , 0.02076  , 0.020178 , 0.020321 , 0.020599 , 0.020565 , 0.020702 , 0.02003  , 0.020296 , 0.019583 , 0.020393 , 0.019691 , 0.020201 , 0.019698 , 0.019599 , 0.01992  , 0.019822 , 0.019159 , 0.019698 , 0.01968  , 0.019121 , 0.019983 , 0.019027 , 0.019585 , 0.018801 , 0.019586 , 0.018674 , 0.018346 , 0.017466 , 0.020832 , 0.019221 , 0.019152 , 0.019963 , 0.01924  , 0.019112 , 0.018706 , 0.018685 , 0.019259 , 0.019202 , 0.019344 , 0.017154 , 0.019861 , 0.018985 , 0.018648 , 0.018435 , 0.019712 , 0.017713 , 0.019417 ]')\n",
      "('valid-errors:', '[0.794856 , 0.435664 , 0.341422 , 0.292223 , 0.252452 , 0.225667 , 0.200872 , 0.183357 , 0.163366 , 0.146823 , 0.13459  , 0.11887  , 0.110786 , 0.103595 , 0.092744 , 0.085543 , 0.085813 , 0.07731  , 0.070736 , 0.06773  , 0.066563 , 0.059302 , 0.056901 , 0.054785 , 0.057483 , 0.051251 , 0.048879 , 0.047169 , 0.046307 , 0.044331 , 0.042347 , 0.043148 , 0.042212 , 0.046799 , 0.038309 , 0.03772  , 0.038847 , 0.036038 , 0.035648 , 0.038238 , 0.034725 , 0.033842 , 0.033965 , 0.033784 , 0.032557 , 0.032227 , 0.032612 , 0.031786 , 0.031697 , 0.030999 , 0.03123  , 0.032952 , 0.030144 , 0.032483 , 0.030741 , 0.029471 , 0.029341 , 0.030481 , 0.030723 , 0.030786 , 0.029197 , 0.029691 , 0.033207 , 0.028171 , 0.02987  , 0.028386 , 0.029348 , 0.029406 , 0.027539 , 0.027434 , 0.027666 , 0.029967 , 0.030724 , 0.028085 , 0.027262 , 0.027345 , 0.027175 , 0.026946 , 0.032116 , 0.026671 , 0.02874  , 0.026653 , 0.040505 , 0.026671 , 0.028464 , 0.029748 , 0.026158 , 0.026244 , 0.026141 , 0.028105 , 0.028684 , 0.027193 , 0.026637 , 0.025756 , 0.027684 , 0.027151 , 0.025662 , 0.026316 , 0.026502 , 0.026729 , 0.02867  , 0.025673 ]')\n"
     ]
    }
   ],
   "source": [
    "#treinando até convertir e obter a lista de erros de treino e erros de validação\n",
    "train_error, val_error = trainer.trainUntilConvergence(dataset=train_data, maxEpochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando a matplotlib para plotar gráficos\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCSB/j/ZhScbdR4VngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a7ced0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotando os erros\n",
    "plt.plot(train_error, 'b', val_error, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error:  0.0209223591255\n",
      "Total error:  0.020204215297\n",
      "Total error:  0.0215656373473\n",
      "Total error:  0.0210758029428\n",
      "Total error:  0.0214408743076\n",
      "Total error:  0.0200102898236\n",
      "Total error:  0.0213306816208\n",
      "Total error:  0.0208636438761\n",
      "Total error:  0.0212751432377\n",
      "Total error:  0.0210123132376\n",
      "Total error:  0.0201081856385\n",
      "Total error:  0.0205437117346\n",
      "Total error:  0.0207376592882\n",
      "Total error:  0.0201336783671\n",
      "Total error:  0.0175132243782\n",
      "Total error:  0.0212992989467\n",
      "Total error:  0.0196048442628\n",
      "Total error:  0.0212245909073\n",
      "Total error:  0.0189970107976\n",
      "Total error:  0.0210683588011\n",
      "Total error:  0.0204661688592\n",
      "Total error:  0.0199462049349\n",
      "Total error:  0.0207270986383\n",
      "Total error:  0.0200870820011\n",
      "Total error:  0.0197121840907\n",
      "Total error:  0.0200077621288\n",
      "Total error:  0.0204730245205\n",
      "Total error:  0.0199676283069\n",
      "Total error:  0.0206713879692\n",
      "Total error:  0.0209412865352\n",
      "Total error:  0.0198099859835\n",
      "Total error:  0.0175577309355\n",
      "Total error:  0.0193921591664\n",
      "Total error:  0.0193399404032\n",
      "Total error:  0.0200004702174\n",
      "Total error:  0.0181129065546\n",
      "Total error:  0.0198685069906\n",
      "Total error:  0.020673905381\n",
      "Total error:  0.0191736747996\n",
      "Total error:  0.0193269739773\n",
      "Total error:  0.0190350886773\n",
      "Total error:  0.0195656661008\n",
      "Total error:  0.0195354356293\n",
      "Total error:  0.0191099043717\n",
      "Total error:  0.0202775727416\n",
      "Total error:  0.0192723134263\n",
      "Total error:  0.0191268662066\n",
      "Total error:  0.0197399824013\n",
      "Total error:  0.0176881050427\n",
      "Total error:  0.0189822926048\n",
      "Total error:  0.0187510651154\n",
      "Total error:  0.0202397839394\n",
      "Total error:  0.019919739123\n",
      "Total error:  0.0199415784838\n",
      "Total error:  0.0198662047722\n",
      "Total error:  0.0198776699609\n",
      "Total error:  0.0198797746458\n",
      "Total error:  0.0181668281235\n",
      "Total error:  0.0188179731369\n",
      "Total error:  0.0193422253514\n",
      "Total error:  0.0192912108501\n",
      "Total error:  0.0182990948831\n",
      "Total error:  0.0198466026679\n",
      "Total error:  0.019586585302\n",
      "Total error:  0.0185260275834\n",
      "Total error:  0.0178470453724\n",
      "Total error:  0.0206024356822\n",
      "Total error:  0.0177130980688\n",
      "Total error:  0.0184985292604\n",
      "Total error:  0.0200488992793\n",
      "Total error:  0.0190210950726\n",
      "Total error:  0.0175727368977\n",
      "Total error:  0.0197975924464\n",
      "Total error:  0.0188223431347\n",
      "Total error:  0.019296919708\n",
      "Total error:  0.0172745859253\n",
      "Total error:  0.0195759838056\n",
      "Total error:  0.0183682547407\n",
      "Total error:  0.0180446011956\n",
      "Total error:  0.0187942948516\n",
      "Total error:  0.0187907593802\n",
      "Total error:  0.0188502381703\n",
      "Total error:  0.0176851392361\n",
      "Total error:  0.0187080589413\n",
      "Total error:  0.0192343391767\n",
      "Total error:  0.0181776340496\n",
      "Total error:  0.0175582748351\n",
      "Total error:  0.0191931954023\n",
      "Total error:  0.0189587918928\n",
      "Total error:  0.0177717005034\n",
      "Total error:  0.0195392933948\n",
      "Total error:  0.0180463484123\n",
      "Total error:  0.0192762114675\n",
      "Total error:  0.0179616421574\n",
      "Total error:  0.0194578513665\n",
      "Total error:  0.0190502606653\n",
      "Total error:  0.0187994362042\n",
      "Total error:  0.0190947334928\n",
      "Total error:  0.0187118496471\n",
      "Total error:  0.0187559961643\n",
      "Total error:  0.0192518432478\n",
      "Total error:  0.0184354773879\n",
      "Total error:  0.0182653463422\n",
      "Total error:  0.0185456665616\n",
      "Total error:  0.0171179989035\n",
      "Total error:  0.0183863203998\n",
      "Total error:  0.017902731188\n",
      "Total error:  0.0182118662601\n",
      "Total error:  0.0182903259573\n",
      "Total error:  0.0181372020138\n",
      "Total error:  0.0189696754406\n",
      "Total error:  0.018443908493\n",
      "Total error:  0.018053008113\n",
      "Total error:  0.0189664027215\n",
      "Total error:  0.0191258704762\n",
      "Total error:  0.0189401729752\n",
      "Total error:  0.0180950855487\n",
      "Total error:  0.019303064924\n",
      "Total error:  0.0178354806568\n",
      "Total error:  0.0188645779077\n",
      "Total error:  0.0181372888053\n",
      "Total error:  0.0174035895289\n",
      "Total error:  0.0181322444419\n",
      "Total error:  0.0181701296464\n",
      "Total error:  0.0179998646226\n",
      "Total error:  0.018562991627\n",
      "Total error:  0.018156746024\n",
      "Total error:  0.0183598051012\n",
      "Total error:  0.0173689062862\n",
      "Total error:  0.0184544884955\n",
      "Total error:  0.0181895841349\n",
      "Total error:  0.0176887786547\n",
      "Total error:  0.018105759479\n",
      "Total error:  0.0181889421652\n",
      "Total error:  0.0179432701557\n",
      "Total error:  0.0175941104771\n",
      "Total error:  0.0179672548656\n",
      "Total error:  0.0178787695951\n",
      "Total error:  0.0179267326408\n",
      "Total error:  0.017697461034\n",
      "Total error:  0.0178487623818\n",
      "Total error:  0.0179550955772\n",
      "Total error:  0.0174777701221\n",
      "Total error:  0.016926883663\n",
      "Total error:  0.0184445504688\n",
      "Total error:  0.0178471865951\n",
      "Total error:  0.0185055344089\n",
      "Total error:  0.0177066209326\n",
      "Total error:  0.0174575208631\n",
      "Total error:  0.0179899350194\n",
      "Total error:  0.0181641723957\n",
      "Total error:  0.0184868743052\n",
      "Total error:  0.0175255232084\n",
      "Total error:  0.0173728571879\n",
      "Total error:  0.01562949108\n",
      "Total error:  0.0180111409468\n",
      "Total error:  0.0184341357759\n",
      "Total error:  0.0179620646324\n",
      "Total error:  0.0174810787436\n",
      "Total error:  0.017879962429\n",
      "Total error:  0.017149254457\n",
      "Total error:  0.0180792393782\n",
      "Total error:  0.0181517941297\n",
      "Total error:  0.0172139500584\n",
      "Total error:  0.0179859240608\n",
      "Total error:  0.0181702393935\n",
      "Total error:  0.0173246355959\n",
      "Total error:  0.0164414363517\n",
      "Total error:  0.018318452603\n",
      "Total error:  0.0173155953166\n",
      "Total error:  0.0166271589065\n",
      "Total error:  0.0170826521526\n",
      "Total error:  0.0174774199827\n",
      "Total error:  0.0171552277696\n",
      "Total error:  0.0179314773032\n",
      "Total error:  0.0171725889148\n",
      "Total error:  0.0172048824019\n",
      "Total error:  0.0174021863407\n",
      "Total error:  0.0165715115944\n",
      "Total error:  0.0179479040903\n",
      "Total error:  0.017412326439\n",
      "Total error:  0.0166312114493\n",
      "Total error:  0.0173557091669\n",
      "Total error:  0.0166221776343\n",
      "Total error:  0.0176499170352\n",
      "Total error:  0.0181608859515\n",
      "Total error:  0.0177730839067\n",
      "Total error:  0.0182104880205\n",
      "Total error:  0.0168634908785\n",
      "Total error:  0.0171700084634\n",
      "Total error:  0.0174997796264\n",
      "Total error:  0.0179530653492\n",
      "Total error:  0.0176367359016\n",
      "Total error:  0.0181687937688\n",
      "Total error:  0.0168455288571\n",
      "Total error:  0.0174976643181\n",
      "Total error:  0.0179621654402\n",
      "Total error:  0.0179725966707\n",
      "Total error:  0.0168749196306\n",
      "Total error:  0.0173613355451\n",
      "Total error:  0.0155046983907\n",
      "Total error:  0.0169030401198\n",
      "Total error:  0.0164287385383\n",
      "Total error:  0.0180931079276\n",
      "Total error:  0.0169929104043\n",
      "Total error:  0.0175979829313\n",
      "Total error:  0.0174475294541\n",
      "Total error:  0.0173618054715\n",
      "Total error:  0.0178616757842\n",
      "Total error:  0.0176696715339\n",
      "Total error:  0.0174126794994\n",
      "Total error:  0.0175065667531\n",
      "Total error:  0.0177872704915\n",
      "Total error:  0.0177851434509\n",
      "Total error:  0.017812323917\n",
      "Total error:  0.017677886961\n",
      "Total error:  0.0174535976049\n",
      "Total error:  0.0176996807189\n",
      "Total error:  0.0175463643463\n",
      "Total error:  0.0167796248281\n",
      "Total error:  0.0178626659326\n",
      "Total error:  0.017203199124\n",
      "Total error:  0.0174541753164\n",
      "Total error:  0.0173392825565\n",
      "Total error:  0.0174514368791\n",
      "Total error:  0.0173745146633\n",
      "Total error:  0.0174637208141\n",
      "Total error:  0.0174475712358\n",
      "Total error:  0.0175239898081\n",
      "Total error:  0.0165887477029\n",
      "Total error:  0.017560559395\n",
      "Total error:  0.0168958023766\n",
      "Total error:  0.0170362758003\n",
      "Total error:  0.0174225181099\n",
      "Total error:  0.0173343361583\n",
      "Total error:  0.0168435183372\n",
      "Total error:  0.0172660338189\n",
      "Total error:  0.0168512107815\n",
      "Total error:  0.0169825858787\n",
      "Total error:  0.016942859537\n",
      "Total error:  0.0172429281015\n",
      "Total error:  0.0169248374444\n",
      "Total error:  0.0169271153903\n",
      "Total error:  0.01712898226\n",
      "Total error:  0.0172960477934\n",
      "Total error:  0.0171675174781\n",
      "Total error:  0.0169971287365\n",
      "Total error:  0.0174529267952\n",
      "Total error:  0.0172451298958\n",
      "Total error:  0.0169667957337\n",
      "Total error:  0.016975664966\n",
      "Total error:  0.0171767446903\n",
      "Total error:  0.0174854979269\n",
      "Total error:  0.017758602944\n",
      "Total error:  0.018124805961\n",
      "Total error:  0.0158075429719\n",
      "Total error:  0.0151423420927\n",
      "Total error:  0.0177556696278\n",
      "Total error:  0.017096247824\n",
      "Total error:  0.0168138932148\n",
      "Total error:  0.018054371577\n",
      "Total error:  0.015544151686\n",
      "Total error:  0.0162171476419\n",
      "Total error:  0.0170598130272\n",
      "Total error:  0.0166160353944\n",
      "Total error:  0.0171457564124\n",
      "Total error:  0.0167972107635\n",
      "Total error:  0.0171966509492\n",
      "Total error:  0.016515888568\n",
      "Total error:  0.0178003688951\n",
      "Total error:  0.0172822420657\n",
      "Total error:  0.0160193102216\n",
      "Total error:  0.0174072388001\n",
      "Total error:  0.0172368284094\n",
      "Total error:  0.0152699449504\n",
      "Total error:  0.0178972677435\n",
      "Total error:  0.016622035541\n",
      "Total error:  0.016629746068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error:  0.0159635995873\n",
      "Total error:  0.016978402941\n",
      "Total error:  0.0171191494405\n",
      "Total error:  0.0165452553973\n",
      "Total error:  0.0162896009643\n",
      "Total error:  0.0166140613044\n",
      "Total error:  0.0161457622037\n",
      "Total error:  0.0165580964366\n",
      "Total error:  0.0166786953775\n",
      "Total error:  0.0169598770679\n",
      "Total error:  0.0171042757368\n",
      "Total error:  0.0167867104919\n",
      "Total error:  0.0169011064006\n",
      "Total error:  0.0165060631594\n",
      "Total error:  0.0159833652169\n",
      "Total error:  0.0175245089061\n",
      "Total error:  0.0173874575131\n",
      "Total error:  0.0171782724483\n",
      "Total error:  0.0172579159803\n",
      "Total error:  0.0162587908696\n",
      "Total error:  0.0165860790311\n",
      "Total error:  0.0173455839321\n",
      "Total error:  0.016966411875\n",
      "Total error:  0.016322215928\n",
      "Total error:  0.0169965098575\n",
      "Total error:  0.0173139188813\n",
      "Total error:  0.0172697127433\n",
      "Total error:  0.0161559905684\n",
      "Total error:  0.0135714427506\n",
      "Total error:  0.0168966321322\n",
      "Total error:  0.0155690740885\n",
      "Total error:  0.0167656923637\n",
      "Total error:  0.0160031403561\n",
      "Total error:  0.0166304417718\n",
      "Total error:  0.0165187376905\n",
      "Total error:  0.0168279695963\n",
      "Total error:  0.016046153057\n",
      "Total error:  0.0155567698706\n",
      "Total error:  0.0168180803134\n",
      "Total error:  0.0167802324756\n",
      "Total error:  0.0174841528211\n",
      "Total error:  0.0171519022981\n",
      "Total error:  0.0165204829709\n",
      "Total error:  0.0154880265813\n",
      "Total error:  0.0173049825608\n",
      "Total error:  0.0162820853615\n",
      "Total error:  0.0166159307125\n",
      "Total error:  0.0170935496348\n",
      "Total error:  0.0168250257877\n",
      "Total error:  0.0164651162119\n",
      "Total error:  0.0166494142316\n",
      "Total error:  0.0173126363134\n",
      "Total error:  0.0161960629727\n",
      "Total error:  0.0171852852288\n",
      "Total error:  0.0171063935446\n",
      "Total error:  0.0165233300704\n",
      "Total error:  0.0166325508042\n",
      "Total error:  0.0164992742036\n",
      "Total error:  0.0170761973519\n",
      "Total error:  0.0173673722256\n",
      "Total error:  0.0170438802597\n",
      "Total error:  0.0163812542977\n",
      "Total error:  0.0169100723785\n",
      "Total error:  0.016463668488\n",
      "Total error:  0.0172681726573\n",
      "Total error:  0.0146570939798\n",
      "Total error:  0.0164411770548\n",
      "Total error:  0.016336411349\n",
      "Total error:  0.0171941664308\n",
      "Total error:  0.016972282952\n",
      "Total error:  0.017422543606\n",
      "Total error:  0.0171203943639\n",
      "Total error:  0.0169211500087\n",
      "Total error:  0.0156757082747\n",
      "Total error:  0.0163136784798\n",
      "Total error:  0.0163250198174\n",
      "Total error:  0.017300966566\n",
      "Total error:  0.0166745843695\n",
      "Total error:  0.0157279573052\n",
      "Total error:  0.0169523986648\n",
      "Total error:  0.0164345111069\n",
      "Total error:  0.0155843597423\n",
      "Total error:  0.0168834702502\n",
      "Total error:  0.0170771875557\n",
      "Total error:  0.0161773209587\n",
      "Total error:  0.0171896608193\n",
      "Total error:  0.0168712813302\n",
      "Total error:  0.0150756839137\n",
      "Total error:  0.0163875531834\n",
      "Total error:  0.016905825134\n",
      "Total error:  0.0164625580134\n",
      "Total error:  0.016325765344\n",
      "Total error:  0.0169156683324\n",
      "Total error:  0.0164074097669\n",
      "Total error:  0.0167726148173\n",
      "Total error:  0.0172040676938\n",
      "Total error:  0.0156253126522\n",
      "Total error:  0.0168331581931\n",
      "Total error:  0.0160627124793\n",
      "Total error:  0.0169308529045\n",
      "Total error:  0.0156437693083\n",
      "Total error:  0.0170665357708\n",
      "Total error:  0.0162333104312\n",
      "Total error:  0.0167517852008\n",
      "Total error:  0.0167748358763\n",
      "Total error:  0.016432577333\n",
      "Total error:  0.015700382565\n",
      "Total error:  0.0159288372819\n",
      "Total error:  0.0146580473771\n",
      "Total error:  0.0166958640887\n",
      "Total error:  0.0155200615901\n",
      "Total error:  0.0165215556757\n",
      "Total error:  0.0154524354963\n",
      "Total error:  0.0172196719077\n",
      "Total error:  0.0162467157008\n",
      "Total error:  0.0160014246682\n",
      "Total error:  0.0153718668611\n",
      "Total error:  0.0161162701744\n",
      "Total error:  0.0174455338095\n",
      "Total error:  0.0163234897134\n",
      "Total error:  0.0160748343676\n",
      "Total error:  0.0159161797664\n",
      "Total error:  0.0156784736755\n",
      "Total error:  0.0155563879233\n",
      "Total error:  0.0162852853192\n",
      "Total error:  0.015007653207\n",
      "Total error:  0.0158200993955\n",
      "Total error:  0.0165011890493\n",
      "Total error:  0.0156824402584\n",
      "Total error:  0.0173547740969\n",
      "Total error:  0.0161043292579\n",
      "Total error:  0.0169716447721\n",
      "Total error:  0.0166702089095\n",
      "Total error:  0.0162328413778\n",
      "Total error:  0.0162634570827\n",
      "Total error:  0.0163890630945\n",
      "Total error:  0.016261766131\n",
      "Total error:  0.0171895896842\n",
      "Total error:  0.0157887320308\n",
      "Total error:  0.0157088557691\n",
      "Total error:  0.0169070207057\n",
      "Total error:  0.0156316705977\n",
      "Total error:  0.0159967057703\n",
      "Total error:  0.0166560244173\n",
      "Total error:  0.0163289184189\n",
      "Total error:  0.0158188350105\n",
      "Total error:  0.0156181093806\n",
      "Total error:  0.016713076082\n",
      "Total error:  0.0154210536181\n",
      "Total error:  0.0166263729553\n",
      "Total error:  0.0156258381749\n",
      "Total error:  0.0170021206221\n",
      "Total error:  0.0151031772819\n",
      "Total error:  0.0158094339563\n",
      "Total error:  0.016637051719\n",
      "Total error:  0.0166925724749\n",
      "Total error:  0.0151395488865\n",
      "Total error:  0.0160128400478\n",
      "Total error:  0.0162097699709\n",
      "Total error:  0.0166935913846\n",
      "Total error:  0.016982177438\n",
      "Total error:  0.0172284881257\n",
      "Total error:  0.0145527299472\n",
      "Total error:  0.0166863495129\n",
      "Total error:  0.0168492384303\n",
      "Total error:  0.01696715079\n",
      "Total error:  0.0158201619906\n",
      "Total error:  0.0159475553446\n",
      "Total error:  0.017171846255\n",
      "Total error:  0.0150315125906\n",
      "Total error:  0.0171324300514\n",
      "Total error:  0.0147729553571\n",
      "Total error:  0.017228940235\n",
      "Total error:  0.0156279181972\n",
      "Total error:  0.0164582934602\n",
      "Total error:  0.0170685775011\n",
      "Total error:  0.0161982262258\n",
      "Total error:  0.0151944372553\n",
      "Total error:  0.017160867352\n",
      "Total error:  0.01470222873\n",
      "Total error:  0.0163072433126\n",
      "Total error:  0.0164519428177\n",
      "Total error:  0.0166047917971\n",
      "Total error:  0.0157438682969\n",
      "Total error:  0.0169824661473\n",
      "Total error:  0.015805020394\n",
      "Total error:  0.0149634334222\n",
      "Total error:  0.0172016862027\n",
      "Total error:  0.015799380544\n",
      "Total error:  0.0152329367635\n",
      "Total error:  0.0169926544983\n",
      "Total error:  0.016160661351\n",
      "Total error:  0.0161177351324\n",
      "Total error:  0.0154842292025\n",
      "Total error:  0.0161879950382\n",
      "Total error:  0.0163131991822\n",
      "Total error:  0.0155873812796\n",
      "Total error:  0.0159063538165\n",
      "Total error:  0.0165254323161\n",
      "Total error:  0.0163091313353\n",
      "Total error:  0.0168102385825\n",
      "Total error:  0.0165039892723\n",
      "Total error:  0.01612283458\n",
      "Total error:  0.0165489936816\n",
      "Total error:  0.0159993199069\n",
      "Total error:  0.0167425100107\n",
      "Total error:  0.0155102616965\n",
      "Total error:  0.0165150221101\n",
      "Total error:  0.0166589860503\n",
      "Total error:  0.0156213295702\n",
      "Total error:  0.0164346303959\n",
      "Total error:  0.0165702609338\n",
      "Total error:  0.0161400210596\n",
      "Total error:  0.0162803445148\n",
      "Total error:  0.0156438201885\n",
      "Total error:  0.0155881058889\n",
      "Total error:  0.017612275369\n",
      "Total error:  0.0162849283935\n",
      "Total error:  0.0167728597638\n",
      "Total error:  0.0164760814326\n",
      "Total error:  0.0160857497102\n",
      "Total error:  0.0158746763536\n"
     ]
    }
   ],
   "source": [
    "#outra maneira de treinar a rede neural\n",
    "trainer.trainOnDataset(train_data, 500) #500 épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saida: 0 correta: 1.000000\n",
      "saida: 0 correta: 0.000000\n",
      "saida: 1 correta: 1.000000\n",
      "saida: 1 correta: 2.000000\n",
      "saida: 1 correta: 1.000000\n",
      "saida: 2 correta: 2.000000\n",
      "saida: 0 correta: 0.000000\n",
      "saida: 0 correta: 0.000000\n",
      "saida: 1 correta: 1.000000\n",
      "saida: 1 correta: 2.000000\n",
      "saida: 0 correta: 0.000000\n",
      "saida: 0 correta: 0.000000\n",
      "saida: 0 correta: 0.000000\n",
      "saida: 0 correta: 0.000000\n",
      "saida: 0 correta: 0.000000\n",
      "saida: 0 correta: 0.000000\n",
      "saida: 1 correta: 1.000000\n",
      "saida: 0 correta: 0.000000\n",
      "saida: 0 correta: 1.000000\n",
      "saida: 1 correta: 1.000000\n",
      "saida: 1 correta: 2.000000\n",
      "saida: 0 correta: 0.000000\n",
      "saida: 0 correta: 1.000000\n",
      "saida: 1 correta: 1.000000\n",
      "saida: 0 correta: 0.000000\n",
      "saida: 1 correta: 1.000000\n",
      "saida: 1 correta: 1.000000\n",
      "saida: 0 correta: 1.000000\n",
      "saida: 1 correta: 1.000000\n",
      "saida: 2 correta: 2.000000\n"
     ]
    }
   ],
   "source": [
    "#testando a rede\n",
    "saidas = rede.activateOnDataset(test_data)\n",
    "for i in range(len(saidas)):\n",
    "    print('saida: %d correta: %f' % (saidas[i], test_data['target'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pybrain.datasets.classification.ClassificationDataSet'>\n",
      "<class 'pybrain.datasets.supervised.SupervisedDataSet'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dt))\n",
    "print(type(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
